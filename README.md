# ğŸ« AWS Data Lake - Sistema de Vendas de Ingressos

## ğŸ“‹ Ãndice
- [VisÃ£o Geral](#-visÃ£o-geral)
- [Arquitetura](#-arquitetura)
- [Camadas do Data Lake](#-camadas-do-data-lake)
- [Fluxo de Dados](#-fluxo-de-dados)
- [Componentes AWS](#-componentes-aws)
- [Deploy](#-deploy)
- [Monitoramento](#-monitoramento)

---

## ğŸ¯ VisÃ£o Geral

Este projeto implementa uma arquitetura completa de **Data Lake** na AWS para democratizaÃ§Ã£o de dados de vendas de ingressos, seguindo as melhores prÃ¡ticas de **Data Mesh** e arquitetura **Medallion** (Bronze â†’ Silver â†’ Gold â†’ Spec).

### ğŸª Caso de Uso
Sistema de vendas de ingressos para shows que processa transaÃ§Ãµes em tempo real e disponibiliza dados analÃ­ticos para times de negÃ³cio via Athena.

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CAMADA TRANSACIONAL                          â”‚
â”‚  DynamoDB (TicketingSystem) â†’ DynamoDB Streams â†’ Lambda Filter     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CAMADA BRONZE (SOR - Raw)                      â”‚
â”‚  Kinesis Firehose â†’ S3 Bronze (JSON) â†’ Glue Crawler â†’ bronze_db    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAMADA SILVER (SOT - Curated)                    â”‚
â”‚  Glue Job (Dedup + Clean) â†’ S3 Silver (Parquet) â†’ silver_db        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CAMADA GOLD (Spec - Aggregated)                    â”‚
â”‚  Glue Job (Filter + Calc) â†’ S3 Gold (Parquet) â†’ gold_db            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAMADA SPEC (Virtual Views)                      â”‚
â”‚              Athena Views â†’ spec_db (Custo Zero)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**[ADICIONAR PRINT: Diagrama de arquitetura completo do AWS Console]**

---

## ğŸ“Š Camadas do Data Lake

### ğŸ¥‰ Camada Bronze (SOR - System of Record)

**Objetivo:** Armazenar dados brutos exatamente como chegam da fonte transacional.

#### ğŸ“¦ Componentes:
- **DynamoDB Table:** `TicketingSystem`
  - PK: `USER#{uuid}` ou `SHOW#{uuid}`
  - SK: `ORDER#{uuid}` ou `TOUR#{uuid}#{year}`
  - Stream habilitado: `NEW_IMAGE`

**[ADICIONAR PRINT: Tabela DynamoDB com dados de exemplo]**

- **Lambda Filter:** `lambda-sales-filter`
  - Filtra apenas registros com `SK` comeÃ§ando em `ORDER#`
  - Adiciona metadados: `evento_tipo`, `ingestion_at`
  - Envia para Kinesis Firehose

**[ADICIONAR PRINT: CÃ³digo da Lambda Filter no console]**

- **Kinesis Firehose:** `show-tickets-bronze-stream`
  - Buffer: 1MB ou 60 segundos
  - Formato: JSON (newline delimited)
  - Particionamento: `vendas_ingressos/year=YYYY/month=MM/day=DD/`

**[ADICIONAR PRINT: ConfiguraÃ§Ã£o do Kinesis Firehose]**

- **S3 Bronze:** `show-tickets-lake-bronze-{id}`
  - Formato: JSON
  - Versionamento: Habilitado
  - Estrutura:
    ```
    vendas_ingressos/
    â”œâ”€â”€ year=2026/
    â”‚   â”œâ”€â”€ month=02/
    â”‚   â”‚   â”œâ”€â”€ day=16/
    â”‚   â”‚   â”‚   â””â”€â”€ *.json
    ```

**[ADICIONAR PRINT: Estrutura de pastas no S3 Bronze]**

- **Glue Crawler:** `bronze-vendas-crawler`
  - Schedule: DiÃ¡rio Ã s 2h UTC
  - Database: `bronze_db`
  - Tabela: `vendas_ingressos`

**[ADICIONAR PRINT: ConfiguraÃ§Ã£o do Glue Crawler Bronze]**

#### ğŸ“‹ Schema Bronze:
```json
{
  "pk": "USER#30f923d5-e4e1-4624-ac98-bb427f78f05d",
  "sk": "ORDER#693917ff-4df4-4389-814a-c6c9136b8a35",
  "details": {
    "status": "CONFIRMED",
    "amount": "190",
    "showid": "2b95692d-5dbf-4b57-8af3-713665229ea7"
  },
  "evento_tipo": "venda_ingresso",
  "ingestion_at": "2026-02-16T15:23:37.626637"
}
```

---

### ğŸ¥ˆ Camada Silver (SOT - Single Source of Truth)

**Objetivo:** Dados limpos, deduplicados e transformados para anÃ¡lise.

#### ğŸ“¦ Componentes:
- **Glue Job:** `silver-transform-job`
  - Tipo: Python Shell (0.0625 DPU - econÃ´mico)
  - Schedule: DiÃ¡rio Ã s 3h UTC (1h apÃ³s crawler Bronze)
  - Biblioteca: `awswrangler` + `pandas`

**[ADICIONAR PRINT: ConfiguraÃ§Ã£o do Glue Job Silver]**

#### ğŸ”„ TransformaÃ§Ãµes:
1. **DeduplicaÃ§Ã£o:** Remove duplicatas por `order_id`, mantendo registro mais recente
2. **Limpeza:**
   - Remove prefixos: `ORDER#`, `USER#`
   - Extrai campos do JSON `details`: `valor_total`, `status`, `show_id`
   - Converte tipos: `valor_total` â†’ float, `ingestion_at` â†’ datetime
3. **Particionamento:** `year`, `month`, `day` (baseado em `ingestion_at`)

**[ADICIONAR PRINT: Logs do Glue Job mostrando transformaÃ§Ãµes]**

- **S3 Silver:** `show-tickets-lake-silver-{id}`
  - Formato: Parquet
  - CompressÃ£o: Snappy
  - Estrutura:
    ```
    vendas_ingressos/
    â”œâ”€â”€ year=2026/
    â”‚   â”œâ”€â”€ month=2/
    â”‚   â”‚   â”œâ”€â”€ day=16/
    â”‚   â”‚   â”‚   â””â”€â”€ *.snappy.parquet
    ```

**[ADICIONAR PRINT: Estrutura de pastas no S3 Silver]**

- **Glue Crawler:** `silver-vendas-crawler`
  - Schedule: DiÃ¡rio Ã s 2h UTC
  - Database: `silver_db`
  - Tabela: `vendas_ingressos`

**[ADICIONAR PRINT: Tabela Silver no Glue Catalog]**

#### ğŸ“‹ Schema Silver:
| Coluna | Tipo | DescriÃ§Ã£o |
|--------|------|-----------|
| `order_id` | string | ID Ãºnico da venda |
| `user_id` | string | ID do usuÃ¡rio (sem prefixo) |
| `valor_total` | double | Valor da venda |
| `status` | string | CONFIRMED, PENDING, CANCELLED |
| `show_id` | string | ID do show |
| `ingestion_at` | timestamp | Data/hora da ingestÃ£o |
| `year` | int | PartiÃ§Ã£o: Ano |
| `month` | int | PartiÃ§Ã£o: MÃªs |
| `day` | int | PartiÃ§Ã£o: Dia |

---

### ğŸ¥‡ Camada Gold (Spec - Materializada)

**Objetivo:** Dados agregados e otimizados para consumo por dashboards e BI.

#### ğŸ“¦ Componentes:
- **Glue Job:** `gold-transform-job`
  - Tipo: Python Shell (0.0625 DPU)
  - Schedule: DiÃ¡rio Ã s 4h UTC (apÃ³s Silver)
  - Biblioteca: `awswrangler` + `pandas`

**[ADICIONAR PRINT: ConfiguraÃ§Ã£o do Glue Job Gold]**

#### ğŸ”„ TransformaÃ§Ãµes:
1. **Filtro:** Apenas vendas com `status = 'CONFIRMED'`
2. **CÃ¡lculos:**
   - `comissao_plataforma`: 10% do `valor_total`
   - `nome_do_show`: ConcatenaÃ§Ã£o `'Show-' + show_id`
3. **Particionamento:** `year`, `month`, `day` (data da venda confirmada)
4. **MSCK REPAIR:** Atualiza partiÃ§Ãµes automaticamente no Athena

**[ADICIONAR PRINT: Query Athena mostrando dados Gold]**

- **S3 Gold:** `show-tickets-lake-gold-{id}`
  - Formato: Parquet
  - CompressÃ£o: Snappy
  - Estrutura:
    ```
    vendas_confirmadas/
    â”œâ”€â”€ year=2026/
    â”‚   â”œâ”€â”€ month=2/
    â”‚   â”‚   â”œâ”€â”€ day=16/
    â”‚   â”‚   â”‚   â””â”€â”€ *.snappy.parquet
    ```

**[ADICIONAR PRINT: Estrutura de pastas no S3 Gold]**

- **Glue Crawler:** `gold-vendas-crawler`
  - Schedule: DiÃ¡rio Ã s 2h UTC
  - Database: `gold_db`
  - Tabela: `vendas_confirmadas`

**[ADICIONAR PRINT: Tabela Gold no Glue Catalog]**

#### ğŸ“‹ Schema Gold:
| Coluna | Tipo | DescriÃ§Ã£o |
|--------|------|-----------|
| `order_id` | string | ID Ãºnico da venda |
| `valor_pago` | double | Valor pago pelo cliente |
| `status` | string | Sempre CONFIRMED |
| `show_id` | string | ID do show |
| `user_id` | string | ID do usuÃ¡rio |
| `data_venda` | timestamp | Data/hora da venda |
| `comissao_plataforma` | double | 10% do valor |
| `nome_do_show` | string | Nome amigÃ¡vel do show |
| `year` | int | PartiÃ§Ã£o: Ano |
| `month` | int | PartiÃ§Ã£o: MÃªs |
| `day` | int | PartiÃ§Ã£o: Dia |

---

### ğŸŒŸ Camada Spec (Virtual - Custo Zero)

**Objetivo:** Views virtuais no Athena para acesso direto pelos times de negÃ³cio.

#### ğŸ“¦ Componentes:
- **Athena Named Query:** `create-vw_vendas_consolidadas_gold`
  - Database: `spec_db`
  - View: `vw_vendas_consolidadas_gold`
  - Custo: Zero armazenamento (apenas query)

**[ADICIONAR PRINT: View no Athena Query Editor]**

#### ğŸ“‹ SQL da View:
```sql
CREATE OR REPLACE VIEW spec_db.vw_vendas_consolidadas_gold AS 
SELECT 
  v.order_id, 
  v.valor_total as valor_pago, 
  v.status, 
  v.show_id,
  v.user_id,
  v.ingestion_at as data_venda,
  v.valor_total * 0.10 as comissao_plataforma 
FROM silver_db.vendas_ingressos v
```

**[ADICIONAR PRINT: Resultado da query na view Spec]**

---

## ğŸ”„ Fluxo de Dados

### â±ï¸ Timeline DiÃ¡ria:

```
00:00 UTC - Lambda Populator gera dados de teste
          â†“
Real-time - DynamoDB Stream â†’ Lambda Filter â†’ Firehose â†’ S3 Bronze
          â†“
02:00 UTC - Crawlers (Bronze, Silver, Gold) catalogam dados
          â†“
03:00 UTC - Glue Job Silver: Bronze â†’ Silver (dedup + clean)
          â†“
04:00 UTC - Glue Job Gold: Silver â†’ Gold (filter + calc)
          â†“
24/7      - Athena Views disponÃ­veis para consulta
```

### ğŸ“ˆ LatÃªncia por Camada:

| Camada | LatÃªncia | AtualizaÃ§Ã£o |
|--------|----------|-------------|
| Bronze | ~1-2 min | Real-time (Firehose buffer) |
| Silver | ~1 hora | DiÃ¡ria Ã s 3h UTC |
| Gold | ~2 horas | DiÃ¡ria Ã s 4h UTC |
| Spec | InstantÃ¢nea | Query on-demand |

**[ADICIONAR PRINT: CloudWatch Metrics mostrando latÃªncias]**

---

## ğŸ› ï¸ Componentes AWS

### ğŸ’¾ Armazenamento:
- **DynamoDB:** Banco transacional NoSQL
- **S3:** Data Lake (Bronze, Silver, Gold)
  - Bronze: `show-tickets-lake-bronze-{id}`
  - Silver: `show-tickets-lake-silver-{id}`
  - Gold: `show-tickets-lake-gold-{id}`

**[ADICIONAR PRINT: Lista de buckets S3]**

### âš¡ Processamento:
- **Lambda Functions:**
  - `lambda-data-populator`: Gera dados de teste
  - `lambda-sales-filter`: Filtra eventos do Stream
- **Kinesis Firehose:** IngestÃ£o em tempo real
- **Glue Jobs:**
  - `silver-transform-job`: TransformaÃ§Ã£o Bronze â†’ Silver
  - `gold-transform-job`: TransformaÃ§Ã£o Silver â†’ Gold

**[ADICIONAR PRINT: Lista de Glue Jobs]**

### ğŸ“š CatÃ¡logo:
- **Glue Data Catalog:**
  - `bronze_db`: Dados brutos (JSON)
  - `silver_db`: Dados limpos (Parquet)
  - `gold_db`: Dados agregados (Parquet)
  - `spec_db`: Views virtuais

**[ADICIONAR PRINT: Databases no Glue Catalog]**

- **Glue Crawlers:**
  - `bronze-vendas-crawler`
  - `silver-vendas-crawler`
  - `gold-vendas-crawler`

**[ADICIONAR PRINT: Lista de Crawlers]**

### ğŸ” Consulta:
- **Amazon Athena:** Query engine SQL serverless
  - Workgroup: `primary`
  - Resultados: Armazenados em cada bucket

**[ADICIONAR PRINT: Athena Query Editor com exemplo de consulta]**

---

## ğŸš€ Deploy

### ğŸ“‹ PrÃ©-requisitos:
- AWS CLI configurado
- Terraform >= 1.6.0
- Python 3.9+
- Conta AWS com permissÃµes adequadas

### ğŸ”§ Passo a Passo:

#### 1ï¸âƒ£ Clone o RepositÃ³rio:
```bash
git clone <repo-url>
cd aws-data-lake
```

#### 2ï¸âƒ£ Configure o Backend (Bootstrap):
```bash
cd infra/terraform/bootstrap
terraform init
terraform apply
```

**[ADICIONAR PRINT: Output do terraform apply do bootstrap]**

#### 3ï¸âƒ£ Deploy da Infraestrutura:
```bash
cd ../envs/dev
terraform init
terraform apply
```

**[ADICIONAR PRINT: Output do terraform apply completo]**

#### 4ï¸âƒ£ Crie a View Spec (Manual):
No console do Athena, execute:
```sql
CREATE OR REPLACE VIEW spec_db.vw_vendas_consolidadas_gold AS 
SELECT 
  v.order_id, 
  v.valor_total as valor_pago, 
  v.status, 
  v.show_id,
  v.user_id,
  v.ingestion_at as data_venda,
  v.valor_total * 0.10 as comissao_plataforma 
FROM silver_db.vendas_ingressos v
```

**[ADICIONAR PRINT: ExecuÃ§Ã£o da query de criaÃ§Ã£o da view]**

#### 5ï¸âƒ£ Teste o Pipeline:
```bash
# Invocar Lambda Populator para gerar dados
aws lambda invoke \
  --function-name lambda-data-populator \
  --region us-east-1 \
  /tmp/response.json
```

**[ADICIONAR PRINT: Response da invocaÃ§Ã£o da Lambda]**

---

## ğŸ“Š Monitoramento

### ğŸ” CloudWatch Logs:

#### Lambda Filter:
```
/aws/lambda/lambda-sales-filter
```
**[ADICIONAR PRINT: Logs da Lambda Filter]**

#### Glue Jobs:
```
/aws-glue/jobs/output
/aws-glue/jobs/error
```
**[ADICIONAR PRINT: Logs do Glue Job Silver]**

### ğŸ“ˆ MÃ©tricas Importantes:

| MÃ©trica | Componente | Alerta |
|---------|------------|--------|
| `IncomingRecords` | Kinesis Firehose | < 1 por 5 min |
| `Duration` | Lambda Filter | > 30s |
| `Errors` | Glue Jobs | > 0 |
| `DataScanned` | Athena | > 10GB/dia |

**[ADICIONAR PRINT: Dashboard CloudWatch com mÃ©tricas]**

### ğŸ”” Alarmes Recomendados:
1. **Firehose Delivery Failures:** > 0
2. **Lambda Errors:** > 5 em 5 minutos
3. **Glue Job Failures:** > 0
4. **S3 Bucket Size:** > 100GB (revisar retenÃ§Ã£o)

**[ADICIONAR PRINT: ConfiguraÃ§Ã£o de alarmes CloudWatch]**

---

## ğŸ’° Custos Estimados

### ğŸ“Š Breakdown Mensal (1M eventos):

| ServiÃ§o | Custo Estimado | ObservaÃ§Ã£o |
|---------|----------------|------------|
| DynamoDB | $5-10 | On-demand pricing |
| Lambda | $1-2 | 1M invocaÃ§Ãµes |
| Kinesis Firehose | $10-15 | IngestÃ£o + transformaÃ§Ã£o |
| S3 | $5-20 | Depende da retenÃ§Ã£o |
| Glue Crawlers | $1-2 | 3 crawlers diÃ¡rios |
| Glue Jobs | $2-3 | Python Shell (0.0625 DPU) |
| Athena | $5-10 | Depende das queries |
| **TOTAL** | **$29-62/mÃªs** | Altamente escalÃ¡vel |

**[ADICIONAR PRINT: AWS Cost Explorer com breakdown]**

### ğŸ’¡ Dicas de OtimizaÃ§Ã£o:
- âœ… Use particionamento para reduzir scan do Athena
- âœ… Parquet + Snappy reduz custos de armazenamento em ~80%
- âœ… Python Shell Jobs sÃ£o 10x mais baratos que Spark
- âœ… Views virtuais (Spec) nÃ£o custam armazenamento
- âœ… Configure lifecycle policies no S3 para dados antigos

---

## ğŸ“ Conceitos Aplicados

### ğŸ›ï¸ Arquitetura Medallion:
- **Bronze (Raw):** Dados brutos, imutÃ¡veis
- **Silver (Curated):** Dados limpos, confiÃ¡veis
- **Gold (Aggregated):** Dados prontos para negÃ³cio
- **Spec (Virtual):** Camada de acesso democratizado

### ğŸŒ Data Mesh:
- **Domain-Oriented:** Cada camada Ã© um domÃ­nio
- **Self-Serve:** Infraestrutura como cÃ³digo (Terraform)
- **Product Thinking:** Dados como produto para consumo
- **Federated Governance:** Glue Catalog centralizado

### ğŸ”„ CDC (Change Data Capture):
- DynamoDB Streams captura mudanÃ§as em tempo real
- Lambda processa apenas eventos relevantes (ORDER#)
- DeduplicaÃ§Ã£o na Silver garante consistÃªncia

---

## ğŸ“š ReferÃªncias

- [AWS Data Lake Best Practices](https://aws.amazon.com/big-data/datalakes-and-analytics/)
- [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)
- [Data Mesh Principles](https://martinfowler.com/articles/data-mesh-principles.html)
- [AWS Glue Documentation](https://docs.aws.amazon.com/glue/)
- [Amazon Athena Best Practices](https://docs.aws.amazon.com/athena/latest/ug/performance-tuning.html)

---

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch: `git checkout -b feature/nova-camada`
3. Commit: `git commit -m 'feat: adiciona camada platinum'`
4. Push: `git push origin feature/nova-camada`
5. Abra um Pull Request

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.

---

## ğŸ‘¥ Autores

Desenvolvido com â¤ï¸ para democratizaÃ§Ã£o de dados na AWS.

**[ADICIONAR PRINT: Arquitetura final completa com todas as camadas]**

---

## ğŸ†˜ Troubleshooting

### âŒ Problema: View nÃ£o aparece no Athena
**SoluÃ§Ã£o:** Execute manualmente a saved query `create-vw_vendas_consolidadas_gold`

### âŒ Problema: Glue Job falha com "Access Denied"
**SoluÃ§Ã£o:** Verifique IAM roles e permissÃµes S3

### âŒ Problema: PartiÃ§Ãµes nÃ£o aparecem
**SoluÃ§Ã£o:** Execute `MSCK REPAIR TABLE` ou aguarde o crawler

### âŒ Problema: Dados duplicados na Silver
**SoluÃ§Ã£o:** Verifique lÃ³gica de deduplicaÃ§Ã£o por `order_id` + `ingestion_at`

**[ADICIONAR PRINT: Exemplo de erro e soluÃ§Ã£o no CloudWatch]**

---

ğŸ‰ **ParabÃ©ns! VocÃª tem um Data Lake completo rodando na AWS!** ğŸ‰
